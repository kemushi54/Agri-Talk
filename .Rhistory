content <-
html_nodes(all.url, "tr td font a") %>%
xml_text
content
content <-
html_nodes(all.url, "tbody tr td font a") %>%
xml_text
content <-
html_nodes(all.url, "tr td font a") %>%
xml_text
content <-
html_nodes(all.url, "table tbody tr td font a") %>%
xml_text
content <-
html_nodes(all.url, "div table tbody tr td font a") %>%
xml_text
content <-
html_nodes(all.url, "tr td font a") %>%
xml_text
content
content <-
html_nodes(all.url, "tr td font") %>%
xml_text
content
installed.packages("rvest")
install.packages("XML")
install.packages("RCurl")
#-- load library
library(rvest)
library(magrittr)
library(data.table)
library(XML)
library(RCurl)
url <- sprintf("http://210.69.150.201/InsectTest/Search.asp?pageNo=%s&keyWord=&CropInum=10268",
1:3)
t <-
getURL(url[1])
t2 <- readHTMLTable(t,
stringsAsFactors = FALSE)
# //*[@id="table32"]/tbody/tr[3]/td/table
test <- read_html(url[1])
# //*[@id="table32"]/tbody/tr[3]/td/table
xpath = '//*[@id="table32"]/tbody/tr[3]/td/table'
test <- read_html(url[1]) %>%
html_nodes(xpath = xpath)
url[1]
test <- read_html(url[1]) %>%
html_nodes("tr td")
test <- read_html(url[1]) %>%
html_nodes("tr td") %>%
html_text
test <- read_html(url[1]) %>%
html_nodes("tr td") %>%
html_table
test[1:10]
test[1]
test[2]
?html_nodes
# //*[@id="table32"]/tbody/tr[3]/td/table
xpath = '//*[@id="table32"]'
test <- read_html(url[1]) %>%
html_nodes(xpath = xpath) %>%
html_table
test <- read_html(url[1]) %>%
html_nodes(xpath = xpath) %>%
html_table(fill = TRUE)
View(test)
View(test[[1]])
install.packages("writexl")
library(writexl)
write_xlsx(test, "pest_checklist.xlsx")
test <- read_html(url[2]) %>%
html_nodes(xpath = xpath) %>%
html_table(fill = TRUE)
test <- read_html(url[2]) %>%
html_nodes(xpath = xpath) %>%
html_table(fill = TRUE) %>%
unlist
read_html(url[x]) %>%
html_nodes(xpath = xpath) %>%
html_table(fill = TRUE)) %>%
do.call(rbind, .)
checklist <-
lapply(1:length(url),
function(x)
read_html(url[x]) %>%
html_nodes(xpath = xpath) %>%
html_table(fill = TRUE)) %>%
do.call(rbind, .)
View(checklist)
View(checklist[[1]])
View(checklist[[2]])
View(checklist[[3]])
dim(checklist[[3]])
dim(checklist[[2]])
read_html(url[x]) %>%
html_nodes(xpath = xpath) %>%
html_table(fill = TRUE)) %>%
do.call(rbind, .) %>%
write_xlsx("pest_checklist.xlsx")
checklist <-
lapply(1:length(url),
function(x)
read_html(url[x]) %>%
html_nodes(xpath = xpath) %>%
html_table(fill = TRUE)) %>%
do.call(rbind, .) %>%
write_xlsx("pest_checklist.xlsx")
checklist <-
lapply(1:length(url),
function(x)
read_html(url[x]) %>%
html_nodes(xpath = xpath) %>%
html_table(fill = TRUE) %>%
as.data.table(.[[1]]))
class(checklist[[1]])
View(checklist[[1]])
checklist <-
lapply(1:length(url),
function(x)
read_html(url[x]) %>%
html_nodes(xpath = xpath) %>%
html_table(fill = TRUE) %>%
as.data.table(.[[1]]) %>%
.[5:55, 1:6])
head(checklist[[1]])
checklist <-
lapply(1:length(url),
function(x)
read_html(url[x]) %>%
html_nodes(xpath = xpath) %>%
html_table(fill = TRUE) %>%
as.data.table(.[[1]]) %>%
.[5:55, 1:6]) %>%
do.call(rbind, .)
checklist <-
lapply(1:length(url),
function(x)
read_html(url[x]) %>%
html_nodes(xpath = xpath) %>%
html_table(fill = TRUE) %>%
as.data.table(.[[1]]) %>%
.[5:55, 1:6]) %>%
do.call(rbind, .) %>%
write_xlsx("pest_checklist.xlsx")
install.packages("rvest")
install.packages("magrittr")
install.packages("data.table")
#-- load library
library(rvest)
library(magrittr)
library(data.table)
install.packages("rvest")
### use pest.sci to get photo url in google search engine
url <- "https://www.google.com.tw/search?q=Ostrinia+furnacalis&source=lnms&tbm=isch&sa=X&ved=0ahUKEwi4ibz_te3eAhXIXLwKHVe5AWIQ_AUIDigB&biw=1280&bih=610"
t <- read_html(url) %>%
html_nodes(, xpath = '//img') %>%
html_attr("src")
#-- load library
library(rvest)
library(magrittr)
library(data.table)
library(RCurl)
library(tidyr)
library(writexl)
library(stringr)
t <- read_html(url) %>%
html_nodes(, xpath = '//img') %>%
html_attr("src")
t[1]
t <- read_html(url) %>%
html_nodes(xpath = '//img') %>%
html_attr("src") %>%
.[1]
### url main page of maiz
url.maiz <- "http://web.tari.gov.tw/techcd/%E8%94%AC%E8%8F%9C/%E6%9E%9C%E8%8F%9C%E9%A1%9E/%E7%8E%89%E7%B1%B3/%E8%9F%B2%E5%AE%B3/%E7%8E%89%E7%B1%B3-%E8%9F%B2%E5%AE%B3.htm"
### get pest url list form main page
pest.list.ori <-
read_html(url.maiz) %>%
html_nodes("tr td font a") %>%
html_attr("href") %>%
.[24:length(.)]
# for C.Common name
pest.C <-
str_replace_all(pest.list.ori,
"玉米-|.htm", "")
# for scraping url
pest.list.url <-
curlEscape(pest.list.ori)
install.packages("RCurl")
library(RCurl)
### url main page of maiz
url.maiz <- "http://web.tari.gov.tw/techcd/%E8%94%AC%E8%8F%9C/%E6%9E%9C%E8%8F%9C%E9%A1%9E/%E7%8E%89%E7%B1%B3/%E8%9F%B2%E5%AE%B3/%E7%8E%89%E7%B1%B3-%E8%9F%B2%E5%AE%B3.htm"
### get pest url list form main page
pest.list.ori <-
read_html(url.maiz) %>%
html_nodes("tr td font a") %>%
html_attr("href") %>%
.[24:length(.)]
# for C.Common name
pest.C <-
str_replace_all(pest.list.ori,
"玉米-|.htm", "")
# for scraping url
pest.list.url <-
curlEscape(pest.list.ori)
url.0 <- "http://web.tari.gov.tw/techcd/%E8%94%AC%E8%8F%9C/%E6%9E%9C%E8%8F%9C%E9%A1%9E/%E7%8E%89%E7%B1%B3/%E8%9F%B2%E5%AE%B3/"
pest.url <- sprintf("%s%s",
url.0, pest.list.url)
### pest scientific name
pest.sci <-
lapply(1:length(pest.url),
function(x)
read_html(pest.url[x]) %>%
html_nodes("i span") %>%
html_text %>%
str_replace_all("\r|\n|\t", "") %>%
.[1])
pest.sci[[1]]
### use lapply get 藥劑資訊/ Scientific name
pest.info <-
lapply(1:length(pest.url),
function(x)
read_html(pest.url[x]) %>%
html_table(fill = TRUE) %>%
lapply(function(i)
if(dim(i)[2] == 5){i}) %>%
do.call(rbind, .) %>%
setDT %>%
.[-1] %>%
.[, Pest := pest.C[x]] %>%
.[, Pest.Sci := pest.sci[[x]]]
) %>%
do.call(rbind, .)
?str_split
str_split(pest.sci[[1]], " ")
str_split(pest.sci[[1]], " ") %>%
.[1:2]
str_split(pest.sci[[1]], " ") %>%
.[[1]][1:2]
str_split(pest.sci[[1]], " ") %>%
.[[1]]
str_split(pest.sci[[1]], " ") %>%
.[[1]][1:2]
t <- str_split(pest.sci[[1]], " ")
t[[1]][1:2]
### use pest.sci - photo url (google search engine)
search.pest.sci <-
str_split(pest.sci, " ")
search.pest.sci[[1]]
### use pest.sci - photo url (google search engine)
search.pest.sci <-
str_split(pest.sci, " ") %>%
.[[1]] %>%
.[1:2]
### use pest.sci - photo url (google search engine)
search.pest.sci <-
str_split(pest.sci, " ") %>%
lapply(function(x)
x[[1]] %>%
.[1:2] %>%
paste(., sep = "+"))
View(search.pest.sci)
search.pest.sci[[1]]
search.pest.sci <-
str_split(pest.sci, " ")
search.pest.sci <-
str_split(pest.sci, " ") %>%
lapply(function(x)
x[[1]])
search.pest.sci[[1]]
search.pest.sci <-
str_split(pest.sci, " ") %>%
lapply(function(x)
x[1:2])
search.pest.sci[[1]]
### use pest.sci - photo url (google search engine)
search.pest.sci <-
str_split(pest.sci, " ") %>%
lapply(function(x)
x[1:2] %>%
paste(., sep = "+"))
search.pest.sci[[1]]
search.pest.sci <-
str_split(pest.sci, " ") %>%
lapply(function(x)
x[1:2])
search.pest.sci[[1]]
paste(search.pest.sci[[1]], sep = "+")
paste(search.pest.sci[[1]], sep = "\\+")
?paste
x[1:2]) %>%
paste(.[1], .[2], sep = "+"))
t <- search.pest.sci[[1]]
paste(t[1], t[2], sep = "+")
x[1:2]) %>%
paste(., collapse = "+")
### use pest.sci - photo url (google search engine)
search.pest.sci <-
str_split(pest.sci, " ") %>%
lapply(function(x)
x[1:2]) %>%
paste(., collapse = "+")
search.pest.sci[[1]]
### use pest.sci - photo url (google search engine)
search.pest.sci <-
str_split(pest.sci, " ") %>%
lapply(function(x)
x[1:2] %>%
paste(., collapse = "+"))
search.pest.sci[[1]]
google.url <- sprintf("https://www.google.com.tw/search?q=%s&source=lnms&tbm=isch&sa=X&ved=0ahUKEwi4ibz_te3eAhXIXLwKHVe5AWIQ_AUIDigB&biw=1280&bih=610",
search.pest.sci)
google.image.url <-
lapply(google.url,
function(x)
read_html %>%
html_nodes(xpath = '//img') %>%
html_attr("src") %>%
.[1])
google.image.url <-
lapply(google.url,
function(x)
read_html %>%
html_nodes(xpath = '//img') %>%
html_attr("src") %>%
.[1])
google.image.url <-
lapply(google.url,
function(x)
read_html(x) %>%
html_nodes(xpath = '//img') %>%
html_attr("src") %>%
.[1])
google.image.url[[1]]
google.image.url[[5]]
pest.sci[[5]]
read_html(x) %>%
html_nodes(xpath = '//img') %>%
html_attr("src") %>%
.[1]) %>%
do.call(rbind, .)
google.image.url <-
lapply(google.url,
function(x)
read_html(x) %>%
html_nodes(xpath = '//img') %>%
html_attr("src") %>%
.[1]) %>%
do.call(rbind, .)
View(google.image.url)
google.image.url[1]
google.image.url[2]
read_html(pest.url[x]) %>%
html_nodes("i span") %>%
html_text %>%
str_replace_all("\r|\n|\t", "") %>%
.[1]) %>%
# turn to vextor
do.call(rbind, .)
### pest scientific name
pest.sci <-
lapply(1:length(pest.url),
function(x)
read_html(pest.url[x]) %>%
html_nodes("i span") %>%
html_text %>%
str_replace_all("\r|\n|\t", "") %>%
.[1]) %>%
# turn to vextor
do.call(rbind, .)
### use pest.sci - photo url (google search engine)
search.pest.sci <-
str_split(pest.sci, " ") %>%
lapply(function(x)
x[1:2] %>%
paste(., collapse = "+"))
search.pest.sci[[1]]
google.url <- sprintf("https://www.google.com.tw/search?q=%s&source=lnms&tbm=isch&sa=X&ved=0ahUKEwi4ibz_te3eAhXIXLwKHVe5AWIQ_AUIDigB&biw=1280&bih=610",
search.pest.sci)
google.image.url <-
lapply(google.url,
function(x)
read_html(x) %>%
html_nodes(xpath = '//img') %>%
html_attr("src") %>%
.[1]) %>%
do.call(rbind, .)
pest.google.image <-
data.frame(pest.Sci = pest.sci,
image.url = google.image.url)
View(pest.google.image)
write(pest.google.image,
"pest_googleIMG.xlsx")
write_xlsx(pest.google.image,
"pest_googleIMG.xlsx")
library(readxl)
library(data.table)
library(magrittr)
data.01 <-
read_xlsx("data/農藥資料查詢.xlsx") %>%
setDT
data.02 <-
fread("data/農藥名稱手冊.csv")
View(data.02)
data.02 <-
fread("data/農藥名稱手冊.csv", encoding = "UTF-8")
View(data.01)
TGAP <-
read_xlsx("data/TGAP甜玉米病蟲害.xlsx") %>%
setDT
View(TGAP)
TGAP <-
read_xlsx("data/TGAP甜玉米病蟲害.xlsx",
sheet = 2) %>%
setDT
agent.list <-
data.02$Name %>% unique
test <-
lapply(agent.list,
function(x)
TGAP[使用防治資材 %like% x, Agent := x] %>%
.[!is.na(Agent)]
)
View(test[[1]])
test <-
lapply(agent.list,
function(x)
TGAP[使用防治資材 %like% x, Agent := x] %>%
.[!is.na(Agent)]
) %>%
do.call(rbind, .)
View(test)
TGAP[, 1:2] %>% unique %>% nrow
test[, list(防治對象, Agent)] %>% unique %>% nrow
test <-
lapply(agent.list,
function(x)
TGAP[使用防治資材 %like% x, Agent := x] %>%
.[!is.na(Agent)]
)
View(test)
View(test[[1]])
View(test[[2]])
x <- 1
test <-
lapply(1:length(agent.list),
function(x)
TGAP[使用防治資材 %like% agent.list[x],
Agent := agent.list[x]] %>%
.[!is.na(Agent)]
) %>%
do.call(rbind, .)
TGAP[使用防治資材 %like% agent.list[x],
Agent := agent.list[x]] %>%
.[!is.na(Agent)]
rm(test)
TGAP[使用防治資材 %like% agent.list[x],
Agent := agent.list[x]] %>%
.[!is.na(Agent)]
agent.list[x]
TGAP[`使用防治資材` %like% agent.list[x],
Agent := agent.list[x]]
a <- TGAP[`使用防治資材` %like% agent.list[x],
Agent := agent.list[x]]
a
View(a)
TGAP[`使用防治資材` %like% agent.list[x],
Agent := agent.list[x]] %>%
.[!is.na(Agent)]
agent.x <- agent.list[x]
TGAP[`使用防治資材` %like% agent.x,
Agent := agent.list[x]] %>%
.[!is.na(Agent)]
TGAP[`使用防治資材` %like% agent.x,
Agent := agent.x] %>%
.[!is.na(Agent)]
TGAP[`使用防治資材` %like% agent.x] %>%
.[, Agent := agent.x]
TGAP <-
read_xlsx("data/TGAP甜玉米病蟲害.xlsx",
sheet = 2) %>%
setDT
a <- TGAP[`使用防治資材` %like% agent.x] %>%
.[, Agent := agent.x]
View(TGAP)
test <-
lapply(1:length(agent.list),
function(x){
agent.x <- agent.list[x]
a <- TGAP[`使用防治資材` %like% agent.x] %>%
.[, Agent := agent.x]
return(a)
}
) %>%
do.call(rbind, .)
View(test)
View(TGAP)
agent.list
x <- 45
agent.x <- agent.list[x]
a <- TGAP[`使用防治資材` %like% agent.x] %>%
.[, Agent := agent.x]
a <- TGAP[`使用防治資材` %like% agent.x]
agent.x
a <- TGAP[`使用防治資材` %like% "護賽寧"]
a <- TGAP[`使用防治資材` %like% "加保利"]
names(TGAP)
a <- TGAP[`使用防治資材` %like% "加保利"]
a <- TGAP[`使用防治資材` %like% "%"]
a <- TGAP[`使用防治資材` %like% "50"]
a <- TGAP[`使用防治資材` %like% "加保利"]
